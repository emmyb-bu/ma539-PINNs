\documentclass[10pt]{article}
% \usepackage{geometry}
% \geometry{margin=0.2in}
% \usepackage[X2]{fontenc}
\usepackage[utf8]{inputenc}
% \usepackage[utf8x]{inputenc}

\nonstopmode
% \usepackage{minted}[cache=false]
\usepackage{graphicx} % Required for including pictures
\usepackage[figurename=Figure]{caption}
\usepackage{float}    % For tables and other floats
\usepackage{amsmath}  % For math
\usepackage{amssymb}  % For more math
\usepackage{fullpage} % Set margins and place page numbers at bottom center
\usepackage{paralist} % paragraph spacing
\usepackage{subfig}   % For subfigures
%\usepackage{physics}  % for simplified dv, and 
\usepackage{enumitem} % useful for itemization
\usepackage{siunitx}  % standardization of si units
\usepackage{hyperref}
\usepackage{mmacells}
\usepackage{listings}
\usepackage{svg}
\usepackage{xcolor, soul}
\usepackage{bm}
% \usepackage{amsthm}  % For math
\usepackage{mathtools}

% \usepackage{setspace}
% \usepackage{listings}
% \usepackage{listings}
% \usepackage[autoload=true]{jlcode}
% \usepackage{pygmentize}



\usepackage[margin=1.8cm]{geometry}
\newcommand{\C}{\mathbb C}
\newcommand{\D}{\bm D}
\newcommand{\R}{\mathbb R}
\newcommand{\Q}{\mathbb Q}
\newcommand{\Z}{\mathbb Z}
\newcommand{\N}{\mathbb N}
\newcommand{\PP}{\mathbb P}
\newcommand{\A}{\mathbb A}
\newcommand{\F}{\mathbb F}
\newcommand{\1}{\mathbf 1}
\newcommand{\ip}[1]{\left< #1 \right>}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\norm}[1]{\left\| #1 \right\|}

\def\Tr{{\rm Tr}}
\def\tr{{\rm tr}}
\def\Var{{\rm Var}}
\def\calA{{\mathcal A}}
\def\calB{{\mathcal B}}
\def\calD{{\mathcal D}}
\def\calE{{\mathcal E}}
\def\calG{{\mathcal G}}
\def\from{{:}}
\def\lspan{{\rm span}}
\def\lrank{{\rm rank}}
\def\bd{{\rm bd}}
\def\acc{{\rm acc}}
\def\cl{{\rm cl}}
\def\sint{{\rm int}}
\def\ext{{\rm ext}}
\def\lnullity{{\rm nullity}}
\DeclareSIUnit\clight{\text{\ensuremath{c}}}
\DeclareSIUnit\fm{\femto\m}
\DeclareSIUnit\hplanck{\text{\ensuremath{h}}}
\usepackage[cache=false]{minted}

% \usepackage{ tipa }

\DeclareUnicodeCharacter{2208}{\ensuremath{\in}}
\DeclareUnicodeCharacter{2082}{\ensuremath{\phantom{}_2}}
\DeclareUnicodeCharacter{03A3}{\ensuremath{\Sigma}}
\DeclareUnicodeCharacter{03C0}{\ensuremath{\pi}}
\DeclareUnicodeCharacter{03C3}{\ensuremath{\sigma}}
\DeclareUnicodeCharacter{03C4}{\ensuremath{\tau}}
\DeclareUnicodeCharacter{0394}{\ensuremath{\Delta}}
\DeclareUnicodeCharacter{2218}{\ensuremath{\circ}}
\DeclareUnicodeCharacter{2A75}{\ensuremath{==}}



\definecolor{mintedbackground}{rgb}{0.902, 0.929, 0.906}

\definecolor{cambridgeblue}{rgb}{0.81, 0.9, 0.84}



\sethlcolor{mintedbackground}
\newcommand{\mathcolorbox}[1]{\colorbox{mintedbackground}{$\displaystyle #1$}}

% \lstdefinelanguage{julia}%
%   {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
%       end,export,false,for,function,immutable,import,importall,if,in,%
%       macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
%       using,while},%
%    sensitive=true,%
% %    alsoother={$},%
%    morecomment=[l]\#,%
%    morecomment=[n]{\#=}{=\#},%
%    morestring=[s]{"}{"},%
%    morestring=[m]{'}{'},%
% }[keywords,comments,strings]%

% \lstset{%
%     language         = Julia,
%     basicstyle       = \ttfamily,
%     keywordstyle     = \bfseries\color{blue},
%     stringstyle      = \color{magenta},
%     commentstyle     = \color{ForestGreen},
%     showstringspaces = false,
% }

% $
\usepackage{setspace}

\doublespacing
\begin{document}
\begin{center}
	\hrule
	\vspace{.4cm}
	{\textbf { \large CAS MA 539 --- Methods of Scientific Computing}}
\end{center}
\textbf{Name:}\ Emmy Blumenthal \hspace{\fill} Final Project Proposal\hspace{\fill}  \textbf{BU ID:} \ U87312711 \\
\textbf{Due Date:}\  Nov 17, 2022   \hspace{\fill} \textbf{Email:}\ emmyb320@bu.edu \ 
\vspace{.4cm}
\hrule

\section*{}

GitHub Repository:  \url{https://github.com/emmyb-bu/ma539-PINNs}

\section*{Physics-Informed Neural Networks}

In this project, I will explore physics-informed neural networks (PINNs) in {\em Julia} using existing, extensible packages that implement neural networks (i.e., Lux.jl), automatic differentiation (e.g., Zygote.jl, ForwardDiff.jl, etc.), and optimization (e.g., Optimisers.jl).
PINNs use neural networks to parameterize solutions by minimizing the difference between the left-hand and right-hand side of a PDE as a least-squares problem.
Specifically, let $u(\vec x,t)$ such that $\partial_t u + \mathcal{N}[u] = 0$ for $\vec x \in \Omega$ and $t \in [0,t_1]$ with boundary data specified as a collection of $n$ points $((\vec x_i,t_i),u_i)_{i=1}^n$ with $\vec x_i \in \partial \Omega$.
Next, the solution $u(\vec x, t|\vec \lambda)$ is modeled as a neural network that takes an array $(\vec x,t)$ as an input and returns a value of $u$, where $\vec \lambda \in \R^p$ are the weights and biases of the neural network.
The PINN is fit by solving the optimization problem:
\begin{align}
	\min_{\vec \lambda \in \R^p} \quad
	\frac{1}{t_1 |\Omega|}
	\int_0^{t_1}
	\int_\Omega\left( | \partial_t u(\vec x,t| \vec \lambda)  + \mathcal{N}[u(\vec x,t | \vec \lambda)]|^2 \right)d \vec x dt + \frac{\alpha }{n}\sum_{i=1}^n|u(\vec x_i,t_i | \vec \lambda) - u_i|^2.
	\label{PINNobj}
\end{align}
Here, the first term enforces that $u(\vec x,t| \vec \lambda)$ obeys the PDE, and the second term enforces that the solution is fit to boundary data; $\alpha>0$ is a hyper-parameter.
To solve the problem on the computer, integrals will be discretized by choosing a set of well-spaced collocation points using a method like Latin hypercube sampling; the factor of $1/t_1|\Omega|$ indicates that after discretization, the first term is a mean-square-error-like term; the boundary data may be discretized boundary conditions.
Derivatives like $\partial_t$ and those involved in $\mathcal{N}$ will be constructed using automatic differentiation of the neural network's inputs.
Additionally, the operator $\mathcal{N}_{\vec \mu}$ can be parameterized by additional parameters $\vec \mu \in \R^q$ which are optimized in addition to the parameters $\vec \lambda$ with the same objective function except the provided data belongs to the region $\Omega$ instead of as boundary conditions.
In a non-ideal case, the data may constitute real-world/experimental data and the objective of the PINN is to learn the operator $\mathcal{N}_{\vec \mu}$.
In this project, I will aim to implement this method in four cases:
\begin{enumerate}
	\item Solving the 1D time-dependent Schr\"odinger equation (\ref{TDSE}) and comparing with solution found using the time-independent Schr\"odinger equation and exact diagonalization.
	\begin{gather}
		i \frac{\partial \psi}{\partial t} = -\frac{1}{2} \frac{\partial^2\psi}{\partial x^2} + V(x) \psi
		\label{TDSE}
	\end{gather}
	The potential function will first be chosen to be $V(x) = 0$, and we will implement Dirichlet boundary conditions (i.e., the `infinite square well').
	Then, we will experiment with various other potentials which may include the quantum harmonic oscillator, the anharmonic oscillator, the double-well potential, and scattering potentials.
	\item Discovering parameters in the potential function used in the 1D time-dependent Schr\"odinger; the potential may be parameterized in three ways:
	\begin{enumerate}
		\item The potential will have a closed analytical form with few parameters that will be discovered
		\item The potential will have a closed analytical form where optimized parameters represent coefficients of a Fourier series expansion of the potential
		\item The potential (maybe the entire Hamiltonian) will be parameterized entirely by a neural network
	\end{enumerate}
	The parameters will be discovered by training on data generated using other solution methods (e.g., exact diagonalization, Crank-Nicolson).
	The generated data could be obscured one step further by sampling from the probability distribution function (PDF) specified by the wave-function to roughly simulate experimental data.
	The loss function would then include a term minimizing the KL-divergence between the PDF specified by the wave-function found using the PINN method and the simulated data.
	\item Solving the Liouville equation (\ref{Liouville1}) from Hamiltonian and statistical mechanics for one particle
	\begin{align}
		\label{Liouville1}
		\frac{\partial \rho}{\partial t}
		=
		-
		\{ \rho, H\}
		=
		\frac{\partial H}{\partial q}
		\frac{\partial \rho}{\partial p}
		-
		\frac{\partial H}{\partial p}
		\frac{\partial \rho}{\partial q}
	\end{align}
	Solving the Liouville equation with PINNs is useful because it is often difficult to avoid negative (and thus unphysical) values of $\rho$ when solving numerically, and parameterization that explicitly prevents negative values of $\rho$ is easy to implement with a neural network.
	It may be interesting to compare some of the results of the Liouville equation (i.e., classical ensembles) to the results of the Schrodinger equation (i.e., quantum ensembles) for the same potentials.
	\item Solving the Liouville equation (\ref{LiouvilleN}) from Hamiltonian and statistical mechanics for $S > N$ particles
	\begin{align}
		\label{LiouvilleN}
		\frac{\partial \rho}{\partial t}
		=
		-
		\{ \rho, H\}
		=
		\sum_{i = 1}^N
		\frac{\partial H}{\partial q_i}
		\frac{\partial \rho}{\partial p_i}
		-
		\frac{\partial H}{\partial p_i}
		\frac{\partial \rho}{\partial q_i}
	\end{align}
\end{enumerate}
These four goals may be too ambitious, so I will proceed through them in order, completing as least item 1 and item 2(a).
Throughout this project, I will additionally familiarize myself with existing packages implementing PINNs (e.g., ModelingToolkit.jl, NeuralPDEs.jl); items 3 and 4 may be implemented with these packages alone depending on difficulty and time available.
Training may involve the use of GPUs which I will access using Boston University's Shared Computing Cluster.
The final product of these explorations will be a set of {\em Julia} scripts which train the PINNs, analyze the results, and visualize solutions along with a project summary which describes successful results, challenges, and how existing code might be expanded or generalized.

\paragraph{References:}

\begin{itemize}
	\item \url{https://arxiv.org/abs/1711.10561}
	\item \url{https://arxiv.org/abs/1711.10566}
	\item \url{https://en.wikipedia.org/wiki/Physics-informed_neural_networks}
	\item \url{https://en.wikipedia.org/wiki/Schrodinger_equation}
	\item \url{https://en.wikipedia.org/wiki/Liouville's_theorem_(Hamiltonian)}
	\item \url{http://lux.csail.mit.edu/stable/}
	\item \url{https://juliadiff.org/ForwardDiff.jl/stable/}
	\item \url{https://fluxml.ai/Optimisers.jl/dev/}
	\item \url{https://neuralpde.sciml.ai/stable/}
\end{itemize}

\end{document}





